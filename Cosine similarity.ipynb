{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the documents\n",
    "doc_trump = \"Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin\"\n",
    "\n",
    "doc_election = \"President Trump says Putin had no political interference is the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election\"\n",
    "\n",
    "doc_putin = \"Post elections, Vladimir Putin became President of Russia. President Putin had served as the Prime Minister earlier in his political career\"\n",
    "\n",
    "documents = [doc_trump, doc_election]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimed</th>\n",
       "      <th>election</th>\n",
       "      <th>friend</th>\n",
       "      <th>friends</th>\n",
       "      <th>interference</th>\n",
       "      <th>lost</th>\n",
       "      <th>mr</th>\n",
       "      <th>outcome</th>\n",
       "      <th>parties</th>\n",
       "      <th>political</th>\n",
       "      <th>president</th>\n",
       "      <th>putin</th>\n",
       "      <th>republican</th>\n",
       "      <th>says</th>\n",
       "      <th>support</th>\n",
       "      <th>trump</th>\n",
       "      <th>winning</th>\n",
       "      <th>witchhunt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc_trump</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261993</td>\n",
       "      <td>0.261993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>0.37282</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>0.261993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261993</td>\n",
       "      <td>0.37282</td>\n",
       "      <td>0.261993</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_election</th>\n",
       "      <td>0.231831</td>\n",
       "      <td>0.32990</td>\n",
       "      <td>0.231831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231831</td>\n",
       "      <td>0.231831</td>\n",
       "      <td>0.32990</td>\n",
       "      <td>0.32990</td>\n",
       "      <td>0.32990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               claimed  election    friend   friends  interference      lost  \\\n",
       "doc_trump     0.000000   0.18641  0.000000  0.523986      0.000000  0.261993   \n",
       "doc_election  0.231831   0.32990  0.231831  0.000000      0.231831  0.000000   \n",
       "\n",
       "                    mr   outcome   parties  political  president    putin  \\\n",
       "doc_trump     0.261993  0.000000  0.000000    0.18641    0.37282  0.18641   \n",
       "doc_election  0.000000  0.231831  0.231831    0.32990    0.32990  0.32990   \n",
       "\n",
       "              republican      says   support    trump   winning  witchhunt  \n",
       "doc_trump       0.261993  0.000000  0.261993  0.37282  0.261993   0.000000  \n",
       "doc_election    0.000000  0.463662  0.000000  0.16495  0.000000   0.231831  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Create the Document Term Matrix\n",
    "# count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['doc_trump', 'doc_election'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'flaten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-bb615d4a088c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflaten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'flaten'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(sparse_matrix, sparse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import sqrt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cosine_similarity(vector1, vector2, ndigits):\n",
    "    \n",
    "#     # Get the common characters between the two character sets\n",
    "#     common_characters = vector1[1].intersection(vector2[1])\n",
    "#     # Sum of the product of each intersection character.\n",
    "#     product_summation = sum(vector1[0][character] * vector2[0][character] for character in common_characters)\n",
    "#     # Gets the length of each vector from the word2vec output.\n",
    "#     length = vector1[2] * vector2[2]\n",
    "#     # Calculates cosine similarity and rounds the value to ndigits decimal places.\n",
    "#     if length == 0:\n",
    "#         # Set value to 0 if word is empty.\n",
    "#         similarity = 0\n",
    "#     else:\n",
    "#         similarity = round(product_summation/length, ndigits)\n",
    "#     return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(word):\n",
    "    # Count the number of characters in each word.\n",
    "    count_characters = Counter(word)\n",
    "    # Gets the set of characters and calculates the \"length\" of the vector.\n",
    "    set_characters = set(count_characters)\n",
    "    length = sqrt(sum(c*c for c in count_characters.values()))\n",
    "    return count_characters, set_characters, length, word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(full_names_list, similarity_threshold, ndigits):\n",
    "    # Initiate an empty list to store results.\n",
    "    results_list = []\n",
    "    # Apply word2vec function to each name and store them in a list.\n",
    "    vector_list = [word2vec(str(i)) for i in full_names_list]\n",
    "\n",
    "    # Two loops to compare each vector with another vector only once.\n",
    "    for i in range(len(vector_list)):\n",
    "        # Get first vector\n",
    "        vector1 = vector_list[i]\n",
    "        for j in range(i+1, len(vector_list)):\n",
    "            # Get the next vector\n",
    "        \n",
    "            vector2 = vector_list[j]\n",
    "            # Calculate cosine similarity\n",
    "            print(\"vactor1 : -\", vector1)\n",
    "            print(\"vactor2 : -\", vector2)\n",
    "            similarity_score = cosine_similarity(vector1, vector2, ndigits)\n",
    "            # Append to results list if similarity score is between 1 and the threshold.\n",
    "            # Note that scores of 1 can be ignored here if we want to exclude people with the same name.\n",
    "            print(similarity_score)\n",
    "            if 1 >= similarity_score >= similarity_threshold:\n",
    "                results_list.append([vector1[3], vector2[3], similarity_score])\n",
    "            else:\n",
    "                pass\n",
    "    # Convert list to dataframe.\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    if len(results_df) != 0:\n",
    "        results_df.columns = ['full_name', 'comparison_name', 'similarity_score']\n",
    "    else:\n",
    "        # Can add error here if there's no results to return if desired.\n",
    "        pass\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vactor1 : - (Counter({'o': 2, 'C': 1, 'n': 1, 'r': 1}), {'o', 'C', 'r', 'n'}, 2.6457513110645907, 'Conor')\n",
      "vactor2 : - (Counter({'o': 2, 'n': 2, 'C': 1, 'r': 1}), {'o', 'C', 'r', 'n'}, 3.1622776601683795, 'Connor')\n",
      "0.956\n",
      "vactor1 : - (Counter({'o': 2, 'C': 1, 'n': 1, 'r': 1}), {'o', 'C', 'r', 'n'}, 2.6457513110645907, 'Conor')\n",
      "vactor2 : - (Counter({'J': 1, 'o': 1, 'n': 1}), {'o', 'J', 'n'}, 1.7320508075688772, 'Jon')\n",
      "0.655\n",
      "vactor1 : - (Counter({'o': 2, 'C': 1, 'n': 1, 'r': 1}), {'o', 'C', 'r', 'n'}, 2.6457513110645907, 'Conor')\n",
      "vactor2 : - (Counter({'J': 1, 'o': 1, 'h': 1, 'n': 1}), {'o', 'J', 'h', 'n'}, 2.0, 'John')\n",
      "0.567\n",
      "vactor1 : - (Counter({'o': 2, 'n': 2, 'C': 1, 'r': 1}), {'o', 'C', 'r', 'n'}, 3.1622776601683795, 'Connor')\n",
      "vactor2 : - (Counter({'J': 1, 'o': 1, 'n': 1}), {'o', 'J', 'n'}, 1.7320508075688772, 'Jon')\n",
      "0.73\n",
      "vactor1 : - (Counter({'o': 2, 'n': 2, 'C': 1, 'r': 1}), {'o', 'C', 'r', 'n'}, 3.1622776601683795, 'Connor')\n",
      "vactor2 : - (Counter({'J': 1, 'o': 1, 'h': 1, 'n': 1}), {'o', 'J', 'h', 'n'}, 2.0, 'John')\n",
      "0.632\n",
      "vactor1 : - (Counter({'J': 1, 'o': 1, 'n': 1}), {'o', 'J', 'n'}, 1.7320508075688772, 'Jon')\n",
      "vactor2 : - (Counter({'J': 1, 'o': 1, 'h': 1, 'n': 1}), {'o', 'J', 'h', 'n'}, 2.0, 'John')\n",
      "0.866\n",
      "  full_name comparison_name  similarity_score\n",
      "0     Conor          Connor             0.956\n",
      "1     Conor             Jon             0.655\n",
      "2     Conor            John             0.567\n",
      "3    Connor             Jon             0.730\n",
      "4    Connor            John             0.632\n",
      "5       Jon            John             0.866\n"
     ]
    }
   ],
   "source": [
    "names_list = ['Conor', 'Connor', 'Jon', 'John']\n",
    "similarity_threshold = 0\n",
    "ndigits = 3\n",
    "results_df = find_similar(names_list, similarity_threshold, ndigits)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-57e95a9bf478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msimilarity_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mget_similar_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mother_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-57e95a9bf478>\u001b[0m in \u001b[0;36mget_similar_texts\u001b[0;34m(text, other_texts)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mother_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msimilarity_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msimilarity_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_kernel' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
